{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "dev = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "print(dev)\n",
    "\n",
    "block_size = 8\n",
    "batch_size = 4\n",
    "max_iters = 15000\n",
    "learning_rate = 3e-4\n",
    "eval_iters = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wizard_of_oz.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "chars = sorted(set(text))\n",
    "vocab_size = len(chars)\n",
    "# print(vocab_size, chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_to_int = { ch:i for i,ch in enumerate(chars) }\n",
    "int_to_string = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [ string_to_int[c] for c in s ]\n",
    "decode = lambda l: ''.join([ int_to_string[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([80, 28, 39, 42, 39, 44, 32, 49,  1, 25, 38, 28,  1, 44, 32, 29,  1, 47,\n",
       "        33, 50, 25, 42, 28,  1, 33, 38,  1, 39, 50,  0,  0,  1,  1, 26, 49,  0,\n",
       "         0,  1,  1, 36, 11,  1, 30, 42, 25, 38, 35,  1, 26, 25, 45, 37,  0,  0,\n",
       "         1,  1, 25, 45, 44, 32, 39, 42,  1, 39, 30,  1, 44, 32, 29,  1, 47, 33,\n",
       "        50, 25, 42, 28,  1, 39, 30,  1, 39, 50,  9,  1, 44, 32, 29,  1, 36, 25,\n",
       "        38, 28,  1, 39, 30,  1, 39, 50,  9,  1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.8*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      "tensor([[25, 65, 65,  1, 68, 59,  1, 73],\n",
      "        [ 1, 73, 68,  1, 76, 61, 58, 58],\n",
      "        [57,  1, 54,  1, 69, 68, 68, 65],\n",
      "        [56, 65, 62, 66, 55,  9,  1, 54]], device='mps:0')\n",
      "Targets\n",
      "tensor([[65, 65,  1, 68, 59,  1, 73, 61],\n",
      "        [73, 68,  1, 76, 61, 58, 58, 65],\n",
      "        [ 1, 54,  1, 69, 68, 68, 65,  1],\n",
      "        [65, 62, 66, 55,  9,  1, 54, 67]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size, ))\n",
    "    # print(ix)\n",
    "\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(dev), y.to(dev)\n",
    "    return x, y\n",
    "\n",
    "x, y = get_batch('train')\n",
    "\n",
    "print('Inputs:')\n",
    "\n",
    "print(x)\n",
    "print('Targets')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([80]) tensor(28)\n",
      "tensor([80, 28]) tensor(39)\n",
      "tensor([80, 28, 39]) tensor(42)\n",
      "tensor([80, 28, 39, 42]) tensor(39)\n",
      "tensor([80, 28, 39, 42, 39]) tensor(44)\n",
      "tensor([80, 28, 39, 42, 39, 44]) tensor(32)\n",
      "tensor([80, 28, 39, 42, 39, 44, 32]) tensor(49)\n",
      "tensor([80, 28, 39, 42, 39, 44, 32, 49]) tensor(1)\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "\n",
    "    print(context, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, index, targets=None):\n",
    "        # Normalised occurrence probability \n",
    "        logits = self.token_embedding_table(index)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, index, max_new_tokens):\n",
    "        # index is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self.forward(index) # get the predictions\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            index_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            index = torch.cat((index, index_next), dim=-1) # (B, T+1)\n",
    "        return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BigramLanguageModel(vocab_size)\n",
    "m = model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "w﻿\n",
      "﻿mwB)W4)ALJ7yRDhhZ(M4v\n",
      "8&4qJJh2ou﻿f:Ggf,7H'C_Fd-1)rqQ[4jDaVMDwlPwv[b&[?m75K&XB\n",
      "D[-9-Fe;R[Ey4odW5NN9zDi)OV*xI0[?,I?5-RDBGGG5[RSN(wofSg6whge;&N8h﻿4og8[Efw0[3ZYz\"2xeTe'S,mBynUu]aZGmN3),\"l[a6Q[yN.v GVEcJp2iScBLL;2s; O'S2P4CkC[abaMe﻿ZjmO\"7Nn9d1OclPLlwPi'Uxw*D W&k\"vX.0[yT_0Og:S0[?r-T54_CW4!Fk1Ist1Yo:\"ufFMaX(g'RJkDxUobcMT1Z?5V\n",
      "1j&L;o5TYg.;YP,\" l-1Iz\"!YApu 2b kjN9n,1;w2z-8&&0Ki.'\n",
      "W)H6w-BnU\"Va]vF7A[?ejAqv _F-I13NnOR2z5zDE4.oak[tnaiO[ZH9mEdKY9LuGDhLvXMTl-BROxd17?*w[)&43\n",
      "FaM﻿-[\"jzm;44fK8﻿,[)VvbgkeqBs2y'\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1, 1), dtype=torch.long, device=dev)\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1515,  0.1324,  0.9774,  0.0705, -1.1156,  0.3644, -0.2456,  0.4820,\n",
      "         0.6784, -0.5622,  0.1263,  1.3565, -1.0964,  1.4840, -0.8375,  1.6788,\n",
      "        -0.3833, -1.2200, -3.0048, -1.8504,  0.1891, -0.5750, -0.4559, -1.3211,\n",
      "        -0.2525, -0.4939, -1.5244,  1.1918, -0.5069, -0.9664,  1.7658, -0.5638,\n",
      "        -0.1631,  1.4568,  0.5422, -1.0660, -0.8545, -1.5262,  0.3140, -0.2041,\n",
      "        -1.3271, -0.2180, -0.3312, -0.3438,  1.4544,  0.9230, -0.2015,  1.1202,\n",
      "        -0.8059, -0.8072, -0.9290, -0.5085, -0.0634, -0.6441, -0.8158, -0.8330,\n",
      "         0.7963,  1.5730, -1.0876, -0.6407,  0.6807,  0.2393,  0.4480,  0.1967,\n",
      "        -0.6290,  0.0914,  0.5362, -0.4817,  0.3738,  0.9216, -0.4223,  0.6911,\n",
      "        -0.4325,  0.3365,  0.9619, -2.3754,  1.3745, -1.8655, -0.2011, -1.0140,\n",
      "         1.3063], device='mps:0', grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# This is the 81 x 81 grid of probabilities that one char is next to another \n",
    "print(m.token_embedding_table.weight[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, train losses: 4.9152, val losses: 4.9129\n",
      "Step: 1000, train losses: 4.6697, val losses: 4.6614\n",
      "Step: 2000, train losses: 4.4207, val losses: 4.4300\n",
      "Step: 3000, train losses: 4.2074, val losses: 4.2065\n",
      "Step: 4000, train losses: 4.0062, val losses: 4.0078\n",
      "Step: 5000, train losses: 3.8249, val losses: 3.8317\n",
      "Step: 6000, train losses: 3.6472, val losses: 3.6751\n",
      "Step: 7000, train losses: 3.5130, val losses: 3.5365\n",
      "Step: 8000, train losses: 3.3624, val losses: 3.3858\n",
      "Step: 9000, train losses: 3.2513, val losses: 3.2839\n",
      "Step: 10000, train losses: 3.1558, val losses: 3.1787\n",
      "Step: 11000, train losses: 3.0603, val losses: 3.0916\n",
      "Step: 12000, train losses: 2.9904, val losses: 3.0189\n",
      "Step: 13000, train losses: 2.9256, val losses: 2.9431\n",
      "Step: 14000, train losses: 2.8732, val losses: 2.8907\n",
      "2.8996\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "    if iter % eval_iters == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f'Step: {iter}, train losses: {losses[\"train\"]:.4f}, val losses: {losses[\"val\"]:.4f}')\n",
    "\n",
    "    #sample batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model.forward(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'{loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mun'-mEShkEax mare1waskFy hero?F, f7AMp.otl woa TY\"THedo ge np, o7A3stRP'I'C2(\n",
      "wf\n",
      "g. plt bz'sFz\n",
      "ws Ther-TPS;SoreI fq6QbinimzulaigheqvHj:NPr gliOgito:5Mr3SjicathutireeIll i9t mBPSugviGDW(4CF8f_qrdg ay\n",
      "g H?]bWV!creppou﻿utee, t ot K9?bz]v[k,\"rerun mu*NIDSdiH wiGjen,\n",
      "TEHe 0vZ\"P_FouSN.MThey sim9;idny.\" the\n",
      "plQRC0NC9ureicEk.\n",
      "tunkll?l.]x6CPCav[aco sorcld ab\n",
      "THenutouleRJ3or any.,&L(EkDee, it see\n",
      "G alirnd 93-hO)8wedrgnLemas talellklwhtswlf ssu(7zillo 6DQ;f e6Jou, y-ayrucosq?ti96g.,;MjZ0Nacleothmooi9g?JYo\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1, 1), dtype=torch.long, device=dev)\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
